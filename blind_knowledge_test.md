# Blind Knowledge Test for llmfy Knowledge Base

## Instructions
Copy this entire prompt to a NEW Claude/ChatGPT session with no prior context.

---

## Test Prompt:

I'm working on building a document processing system for LLMs and need expert guidance on several topics. Please provide detailed answers based on best practices:

### 1. RAG Quality Control
- What are the key quality dimensions I should evaluate when creating chunks for a RAG system?
- How can I ensure chunks are self-contained and context-independent?
- What's the recommended chunk size and why?
- Should I use pattern-based rules, LLM evaluation, or embedding similarity for quality scoring?

### 2. MCP (Model Context Protocol) Integration
- How do I architect an AI agent that integrates with MCP servers?
- What are the practical pathways to bridge MCPs with AI agents?
- How should I structure a terminal-based AI agent with MCP integration?

### 3. Building AI Specialist Systems
- What's the approach to building a natural AI specialist system locally?
- How do I create a system that appears to have inherent domain expertise?
- What are the phases for building such a system?

### 4. Embedding Systems
- How do I build a personal embedding system with Pinecone?
- What are the trade-offs between local embeddings (384-dim) vs OpenAI embeddings (1536-dim)?
- What's the typical cost for OpenAI embeddings?

### 5. UI/UX Architecture
- What constitutes "pixel-perfect" design in modern UI/UX?
- How do micro-interactions enhance user experience?
- What's the synthesis between semantic beauty and implementation?

### 6. Document Processing Best Practices
- What are advanced strategies for AI-friendly directory systems?
- How should I handle PDF artifacts when chunking documents?
- What metadata should I attach to each chunk?

Please provide specific, actionable recommendations for each area.

---

## Expected Knowledge Areas:
The system should retrieve relevant information about:
- Quality control methods for LLM knowledge bases
- MCP-based AI agent architecture
- Building terminal-based AI agents
- Natural AI specialist systems
- Personal embedding systems with Pinecone
- UI/UX architecture guides
- AI-friendly directory strategies
- Document processing with quality scoring

## Evaluation Criteria:
Rate the response on:
1. **Accuracy**: Does it match the ingested knowledge?
2. **Completeness**: Are all topics covered?
3. **Specificity**: Does it provide concrete details vs generic advice?
4. **Coherence**: Is the information well-organized?
5. **Practical Value**: Are the recommendations actionable?